{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpaU2jQ92hey"
      },
      "outputs": [],
      "source": [
        "#THEORY QUESTIONS\n",
        "'''\n",
        "\n",
        "Q1] What is hypothesis testing in statistics?\n",
        "\n",
        "Ans- Hypothesis testing in statistics is a method used to make decisions or inferences about a population based on sample data.\n",
        "     It helps you determine whether there is enough evidence in a sample to support a specific claim about the population.\n",
        "\n",
        "Q2] What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "\n",
        "Ans- 1. Null Hypothesis (H‚ÇÄ):\n",
        "        * It's the default assumption or starting point.\n",
        "        * It states that there is no effect, no difference, or no change.\n",
        "        * It‚Äôs what you try to disprove or test against.\n",
        "\n",
        "    2. Alternative Hypothesis (H‚ÇÅ or Ha):\n",
        "        * It‚Äôs the opposite of the null hypothesis.\n",
        "        * It suggests that there is an effect, a difference, or a change.\n",
        "        * It‚Äôs what you're trying to find evidence for.\n",
        "\n",
        "Q3] What is the significance level in hypothesis testing, and why is it important?\n",
        "\n",
        "Ans- The significance level (usually written as Œ±, alpha) is a threshold you set before doing a hypothesis test. It tells you how much\n",
        "     risk of making a wrong decision (a false positive) you're willing to accept.\n",
        "\n",
        "Q4] What does a P-value represent in hypothesis testing?\n",
        "\n",
        "Ans- The p-value is the probability of getting your observed results (or something even more extreme) if the null hypothesis were true.\n",
        "\n",
        "Q5] How do you interpret the P-value in hypothesis testing?\n",
        "\n",
        "Ans- ‚úÖ Step 1: Understand the Hypotheses\n",
        "        Null hypothesis (H‚ÇÄ): No effect, no difference, status quo.\n",
        "\n",
        "        Alternative hypothesis (H‚ÇÅ): There is an effect or difference.\n",
        "\n",
        "     ‚úÖ Step 2: Run the Test and Get a P-value\n",
        "        You use a statistical test (like a t-test, z-test, etc.) and get a p-value ‚Äî a number between 0 and 1.\n",
        "\n",
        "    ‚úÖ Step 3: Compare the P-value to Your Significance Level (Œ±)\n",
        "       Usually, Œ± = 0.05 (5%) unless stated otherwise.\n",
        "\n",
        "Q6] What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "\n",
        "Ans- Type I Error (False Positive): You reject the null hypothesis (H‚ÇÄ), but it was actually true.\n",
        "     Type II Error (False Negative): You fail to reject the null hypothesis, but it was actually false.\n",
        "\n",
        "Q7] What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "\n",
        "Ans- In two-tailed Test you're testing for any significant difference, either higher or lower.You don't care about the direction of the\n",
        "     effect ‚Äî just that there is one.\n",
        "\n",
        "     In One-Tailed Test you're testing for a difference in one specific direction ‚Äî greater than or less than.\n",
        "\n",
        "Q8] What is the Z-test, and when is it used in hypothesis testing?\n",
        "\n",
        "Ans- A Z-test is a statistical method used to determine whether there is a significant difference between:\n",
        "         A sample mean and a population mean, or two sample means.\n",
        "\n",
        "Q9] How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "\n",
        "Ans- A Z-score tells you how many standard deviations a data point (or sample mean) is from the population mean.\n",
        "\n",
        "üìä In Hypothesis Testing:\n",
        "The Z-score helps you figure out how extreme your sample result is, assuming the null hypothesis (H‚ÇÄ) is true.\n",
        "\n",
        "üßÆ How to Calculate a Z-score\n",
        "üîπ For a sample mean:\n",
        "                        ùëç= ùë•Àâ‚àíùúá/ùúé/root ùëõ\n",
        "\n",
        "Where:\n",
        "ùë•- = sample mean\n",
        "ùúá = population mean under H‚ÇÄ\n",
        "ùúé = population standard deviation\n",
        "ùëõ = sample size\n",
        "\n",
        "üîπ For a single data point:\n",
        "                            ùëç = ùë•‚àíùúá/ùúé\n",
        "Where:\n",
        "x = individual data point\n",
        "ùúá = population mean\n",
        "ùúé = population standard deviation\n",
        "\n",
        "A Z-score of 0 means the value is exactly at the mean.A positive Z-score means the value is above the mean.A negative Z-score means\n",
        " the value is below the mean.\n",
        "\n",
        "Q10] What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "\n",
        "Ans- The T-distribution (or Student's t-distribution) is a probability distribution that‚Äôs very similar to the normal distribution, but it has\n",
        "     thicker tails ‚Äî meaning it accounts for more variability, especially in smaller samples.It‚Äôs used in statistics when you're doing inference\n",
        "    (like confidence intervals or hypothesis tests) and don‚Äôt have full information about the population.\n",
        "\n",
        "Q11] What is the difference between a Z-test and a T-test?\n",
        "\n",
        "Ans-\n",
        "         Feature\t                            Z-test                                                                  \tT-test\n",
        "Population Standard Deviation  \t           Must be known                                                           Must be unknown\n",
        "Sample Size\t                           Typically large (n ‚â• 30)\t                                                Typically small (n < 30)\n",
        "Distribution\t              Uses the Normal Distribution (Z-distribution)  \t                              Uses the T-distribution (t-distribution)\n",
        "‚ÄãUse Case\t              When you know the population œÉ and the sample size is large      When you don't know the population œÉ and the sample size is small\n",
        "\n",
        "\n",
        "Q12] What is the T-test, and how is it used in hypothesis testing?\n",
        "\n",
        "Ans- The T-test is a statistical test used to compare the mean of a sample to a known value (usually the population mean), or to compare the\n",
        "     means of two groups. It‚Äôs especially useful when:The sample size is small (typically n < 30).The population standard deviation (œÉ) is unknown,\n",
        "     so we must use the sample standard deviation (s) instead.\n",
        "\n",
        "Q13] What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "\n",
        "Ans- Similarities:\n",
        "  *Both are used for hypothesis testing to compare a sample mean to a population mean (or two sample means).\n",
        "  *Both test if the observed sample mean is significantly different from the expected population mean (under the null hypothesis).\n",
        "  *Both use the central limit theorem, which says that as sample size increases, the distribution of sample means will approach a normal distribution.\n",
        "\n",
        "Q14] What is a confidence interval, and how is it used to interpret statistical results?\n",
        "\n",
        "Ans- A confidence interval is a range of values, derived from the sample data, that is used to estimate an unknown population parameter (such as\n",
        "     a population mean or proportion). The interval gives you a range of values within which you are reasonably confident the true population\n",
        "     parameter lies.\n",
        "\n",
        "Q15] What is the margin of error, and how does it affect the confidence interval?\n",
        "\n",
        "Ans- The margin of error (MOE) is a measure of the uncertainty or precision in an estimate. It tells you how much the sample statistic (like the\n",
        "     sample mean) might differ from the true population parameter (like the population mean).In the context of confidence intervals, the margin of\n",
        "     error is the amount added to and subtracted from the sample statistic to create the range that forms the confidence interval.The larger the\n",
        "     margin of error, the wider the confidence interval, indicating more uncertainty in the estimate.\n",
        "\n",
        "Q16] How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "\n",
        "Ans- Bayes' Theorem is a fundamental concept in probability and statistics, allowing us to update our beliefs about the probability of an event\n",
        "     based on new evidence. It is especially useful in situations where we want to refine our understanding of the likelihood of an event occurring,\n",
        "     given additional data or prior knowledge.\n",
        "\n",
        "Q17]  What is the Chi-square distribution, and when is it used?\n",
        "\n",
        "Ans- The Chi-square distribution is a probability distribution that is widely used in statistics, particularly for hypothesis testing and in\n",
        "     scenarios involving categorical data. It is a special case of the gamma distribution and is used primarily in tests that assess whether\n",
        "     there is a significant difference between observed and expected frequencies in categorical data.\n",
        "\n",
        "Q18] What is the Chi-square goodness of fit test, and how is it applied?\n",
        "\n",
        "Ans- The Chi-square goodness of fit test is a statistical test used to determine whether there is a significant difference between the observed\n",
        "     frequencies and the expected frequencies of a categorical variable. It helps to assess how well the observed data matches a specific\n",
        "     theoretical distribution.\n",
        "\n",
        "Q19] What is the F-distribution, and when is it used in hypothesis testing?\n",
        "\n",
        "Ans- The F-distribution is a probability distribution that is used in hypothesis testing, especially in the context of comparing variances across\n",
        "     multiple groups or populations. It is particularly important in analysis of variance (ANOVA), regression analysis, and testing the equality of\n",
        "    variances between two or more groups.\n",
        "\n",
        "Q20] What is an ANOVA test, and what are its assumptions?\n",
        "\n",
        "Ans- ANOVA (Analysis of Variance) is a statistical test used to determine if there are any significant differences between the means of three or\n",
        "     more groups. It compares the variation within each group (how much the data points vary within each group) to the variation between the groups\n",
        "    (how much the group means differ from each other). The goal of ANOVA is to test whether at least one group mean is significantly different from\n",
        "     the others.\n",
        "\n",
        "     Assumptions of the ANOVA Test:\n",
        "For ANOVA to produce valid and reliable results, several assumptions must be met:\n",
        "\n",
        "Independence of Observations:\n",
        "\n",
        "The data points in each group should be independent of each other. This means the value of one observation in a group should not influence the value of another observation in the same group or in another group.\n",
        "\n",
        "Violation: If data points are related (e.g., repeated measurements from the same subjects), this assumption is violated, and a repeated measures ANOVA might be needed instead.\n",
        "\n",
        "Normality:\n",
        "\n",
        "The data within each group should be approximately normally distributed. While ANOVA is somewhat robust to violations of normality when sample sizes are large (thanks to the Central Limit Theorem), this assumption is more important when sample sizes are small.\n",
        "\n",
        "Violation: If data is significantly skewed, transformation of data or using non-parametric tests may be necessary.\n",
        "\n",
        "Homogeneity of Variances (Homoscedasticity):\n",
        "\n",
        "The variance (spread) within each group should be approximately equal. This assumption is crucial because ANOVA tests the ratio of variances (between-group vs. within-group). If variances are unequal, the results of the test may be misleading.\n",
        "\n",
        "Violation: If variances are unequal (i.e., heteroscedasticity), a Welch‚Äôs ANOVA or a non-parametric test like the Kruskal-Wallis test can be used.\n",
        "\n",
        "\n",
        "Q21] What are the different types of ANOVA tests?\n",
        "\n",
        "Ans- Types of ANOVA:\n",
        "One-Way ANOVA:\n",
        "\n",
        "Compares the means of three or more groups based on a single factor (independent variable).\n",
        "\n",
        "Example: Testing whether different teaching methods (Group A, Group B, Group C) result in different average test scores.\n",
        "\n",
        "Two-Way ANOVA:\n",
        "\n",
        "Compares the means of groups based on two factors (independent variables).\n",
        "\n",
        "Example: Testing the effects of teaching method and student gender on test scores.\n",
        "\n",
        "Repeated Measures ANOVA:\n",
        "\n",
        "Used when the same subjects are used for each treatment (i.e., repeated measurements are taken from the same group).\n",
        "\n",
        "Example: Testing the effect of different diets on the same group of individuals at different times.\n",
        "\n",
        "Q22] What is the F-test, and how does it relate to hypothesis testing?\n",
        "\n",
        "Ans- The F-test is a statistical test used to compare the variances of two or more groups to determine if they are significantly different. It is\n",
        "    based on the F-distribution, and it is often used in contexts such as Analysis of Variance (ANOVA), regression analysis, and testing the\n",
        "     equality of variances.The F-test is used to test the null hypothesis that the variances (or group means) across different groups are equal.\n",
        "     It is used in hypothesis testing to assess whether there is more variability between groups than within groups, which can indicate a significant\n",
        "    difference between groups.\n",
        "\n",
        "\n",
        "    '''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PRACTICAL QUESTIONS\n",
        "\n",
        "\n",
        "#Q1] Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results.\n",
        "\n",
        "Ans- import math\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Input values\n",
        "population_mean = 100      # Œº\n",
        "population_std_dev = 15    # œÉ\n",
        "sample_mean = 106          # XÃÑ\n",
        "sample_size = 30           # n\n",
        "alpha = 0.05               # Significance level\n",
        "\n",
        "# Step 1: Calculate the Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std_dev / math.sqrt(sample_size))\n",
        "\n",
        "# Step 2: Calculate the p-value (two-tailed test)\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))  # For two-tailed test\n",
        "\n",
        "# Step 3: Interpretation\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Conclusion\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between the sample and population mean.\")"
      ],
      "metadata": {
        "id": "rbyc54LxBdS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2]  Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python.\n",
        "\n",
        "Ans- import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Step 1: Simulate random sample data\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample_size = 30\n",
        "true_mean = 52\n",
        "sample = np.random.normal(loc=true_mean, scale=10, size=sample_size)\n",
        "\n",
        "# Step 2: Set population mean (under H‚ÇÄ)\n",
        "population_mean = 50\n",
        "\n",
        "# Step 3: Perform one-sample t-test\n",
        "t_statistic, p_value = stats.ttest_1samp(sample, population_mean)\n",
        "\n",
        "# Step 4: Output results\n",
        "print(\"Sample mean:\", np.mean(sample))\n",
        "print(\"T-statistic:\", round(t_statistic, 4))\n",
        "print(\"P-value:\", round(p_value, 4))\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: Significant difference found.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference found.\")"
      ],
      "metadata": {
        "id": "tUS2KDRZXVkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3] @ Implement a one-sample Z-test using Python to compare the sample mean with the population mean.\n",
        "\n",
        "Ans- import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Step 1: Simulate sample data\n",
        "np.random.seed(0)\n",
        "sample = np.random.normal(loc=105, scale=15, size=40)  # Sample from a normal distribution\n",
        "\n",
        "# Known population parameters\n",
        "population_mean = 100      # Œº\n",
        "population_std_dev = 15    # œÉ (known)\n",
        "\n",
        "# Step 2: Calculate sample statistics\n",
        "sample_mean = np.mean(sample)\n",
        "sample_size = len(sample)\n",
        "\n",
        "# Step 3: Compute Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std_dev / np.sqrt(sample_size))\n",
        "\n",
        "# Step 4: Compute p-value for a two-tailed test\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Step 5: Output results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 6: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: Sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between sample and population mean.\")\n",
        "‚úÖ Example Output:\n",
        "yaml\n",
        "Copy\n",
        "Edit\n",
        "Sample Mean: 106.29\n",
        "Z-score: 2.6544\n",
        "P-value: 0.0079\n",
        "Reject the null hypothesis: Sample mean is significantly different from the population mean"
      ],
      "metadata": {
        "id": "5SNvzx-qXwTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4]  Perform a two-tailed Z-test using Python and visualize the decision region on a plot.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Step 1: Simulate sample data\n",
        "np.random.seed(42)\n",
        "sample = np.random.normal(loc=105, scale=10, size=30)\n",
        "\n",
        "# Step 2: Define population parameters\n",
        "population_mean = 100\n",
        "population_std_dev = 10\n",
        "sample_mean = np.mean(sample)\n",
        "sample_size = len(sample)\n",
        "\n",
        "# Step 3: Perform Z-test\n",
        "z_score = (sample_mean - population_mean) / (population_std_dev / np.sqrt(sample_size))\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))  # Two-tailed p-value\n",
        "\n",
        "# Step 4: Print results\n",
        "print(f\"Sample mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 5: Set significance level\n",
        "alpha = 0.05\n",
        "z_critical = norm.ppf(1 - alpha / 2)  # Two-tailed\n",
        "\n",
        "# Step 6: Plot the normal distribution with decision regions\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x, 0, 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(x, y, label=\"Standard Normal Distribution\", color=\"blue\")\n",
        "\n",
        "# Shade critical regions\n",
        "plt.fill_between(x, y, where=(x < -z_critical) | (x > z_critical), color='red', alpha=0.3, label='Rejection Region (Œ±=0.05)')\n",
        "\n",
        "# Mark Z-score\n",
        "plt.axvline(z_score, color='green', linestyle='--', label=f'Z-score = {z_score:.2f}')\n",
        "plt.axvline(-z_critical, color='red', linestyle='--')\n",
        "plt.axvline(z_critical, color='red', linestyle='--')\n",
        "\n",
        "# Labels and legend\n",
        "plt.title(\"Two-Tailed Z-Test with Rejection Regions\")\n",
        "plt.xlabel(\"Z\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Decision\n",
        "if abs(z_score) > z_critical:\n",
        "    print(\"Reject the null hypothesis: Sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference.\")"
      ],
      "metadata": {
        "id": "oPF7P3orYBW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5] Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def visualize_type1_type2_errors(mu_0, mu_1, sigma, n, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Visualizes Type I and Type II errors for hypothesis testing.\n",
        "\n",
        "    Parameters:\n",
        "    - mu_0: Mean under H0\n",
        "    - mu_1: Mean under H1\n",
        "    - sigma: Population standard deviation\n",
        "    - n: Sample size\n",
        "    - alpha: Significance level (default = 0.05)\n",
        "    \"\"\"\n",
        "    # Standard error\n",
        "    se = sigma / np.sqrt(n)\n",
        "\n",
        "    # Critical value for two-tailed test\n",
        "    z_critical = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    # Decision boundaries under H0\n",
        "    lower_crit = mu_0 - z_critical * se\n",
        "    upper_crit = mu_0 + z_critical * se\n",
        "\n",
        "    # Create x range covering both distributions\n",
        "    x = np.linspace(mu_0 - 4*se, mu_1 + 4*se, 1000)\n",
        "\n",
        "    # H0 and H1 distributions\n",
        "    h0_pdf = norm.pdf(x, mu_0, se)\n",
        "    h1_pdf = norm.pdf(x, mu_1, se)\n",
        "\n",
        "    # Plot the distributions\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(x, h0_pdf, label=\"Null Hypothesis (H‚ÇÄ)\", color='blue')\n",
        "    plt.plot(x, h1_pdf, label=\"Alternative Hypothesis (H‚ÇÅ)\", color='green')\n",
        "\n",
        "    # Shade Type I error (Œ±)\n",
        "    plt.fill_between(x, h0_pdf, where=(x < lower_crit) | (x > upper_crit), color='red', alpha=0.3, label='Type I Error (Œ±)')\n",
        "\n",
        "    # Shade Type II error (Œ≤)\n",
        "    plt.fill_between(x, h1_pdf, where=(x >= lower_crit) & (x <= upper_crit), color='orange', alpha=0.3, label='Type II Error (Œ≤)')\n",
        "\n",
        "    # Vertical lines for critical values\n",
        "    plt.axvline(lower_crit, color='black', linestyle='--', label='Critical Values')\n",
        "    plt.axvline(upper_crit, color='black', linestyle='--')\n",
        "\n",
        "    # Calculate beta (Type II error probability)\n",
        "    beta = norm.cdf(upper_crit, mu_1, se) - norm.cdf(lower_crit, mu_1, se)\n",
        "\n",
        "    plt.title(\"Type I and Type II Errors in Hypothesis Testing\")\n",
        "    plt.xlabel(\"Sample Mean\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Critical region: [{lower_crit:.2f}, {upper_crit:.2f}]\")\n",
        "    print(f\"Type I Error (Œ±): {alpha}\")\n",
        "    print(f\"Type II Error (Œ≤): {beta:.4f}\")\n",
        "    print(f\"Power of the test (1 - Œ≤): {1 - beta:.4f}\")\n",
        "\n",
        "# Example usage\n",
        "visualize_type1_type2_errors(mu_0=100, mu_1=105, sigma=15, n=30, alpha=0.05)"
      ],
      "metadata": {
        "id": "Hfho05YUYSJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q6] Write a Python program to perform an independent T-test and interpret the results.\n",
        "\n",
        "Ans- import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Step 1: Simulate data for two independent groups\n",
        "np.random.seed(42)\n",
        "group_a = np.random.normal(loc=100, scale=10, size=30)  # Mean = 100, std = 10\n",
        "group_b = np.random.normal(loc=105, scale=10, size=30)  # Mean = 105, std = 10\n",
        "\n",
        "# Step 2: Perform the independent (two-sample) t-test\n",
        "t_stat, p_value = stats.ttest_ind(group_a, group_b)\n",
        "\n",
        "# Step 3: Output results\n",
        "print(f\"Group A mean: {np.mean(group_a):.2f}\")\n",
        "print(f\"Group B mean: {np.mean(group_b):.2f}\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the two groups.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between the two groups.\")\n"
      ],
      "metadata": {
        "id": "k7Dlp8NXYjLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q7] Perform a paired sample T-test using Python and visualize the comparison results.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Step 1: Simulate paired data\n",
        "np.random.seed(1)\n",
        "n = 30\n",
        "before = np.random.normal(loc=70, scale=10, size=n)\n",
        "after = before + np.random.normal(loc=5, scale=5, size=n)  # Improvement after treatment\n",
        "\n",
        "# Step 2: Paired sample t-test\n",
        "t_stat, p_value = ttest_rel(before, after)\n",
        "\n",
        "# Step 3: Output results\n",
        "print(f\"Mean before: {np.mean(before):.2f}\")\n",
        "print(f\"Mean after: {np.mean(after):.2f}\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: Significant difference between paired samples.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between paired samples.\")\n",
        "\n",
        "# Step 5: Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(n):\n",
        "    plt.plot([1, 2], [before[i], after[i]], color='gray', marker='o')\n",
        "\n",
        "plt.xticks([1, 2], ['Before', 'After'])\n",
        "plt.title('Paired Sample Scores: Before vs After')\n",
        "plt.ylabel('Score')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q9wChyVJY2op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q8]  Simulate data and perform both Z-test and T-test, then compare the results using Python.\n",
        "\n",
        "Ans- import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Step 1: Simulate sample data\n",
        "np.random.seed(42)\n",
        "sample = np.random.normal(loc=102, scale=10, size=30)  # True mean slightly above population mean\n",
        "sample_mean = np.mean(sample)\n",
        "sample_std = np.std(sample, ddof=1)\n",
        "n = len(sample)\n",
        "\n",
        "# Population parameters (known for Z-test)\n",
        "population_mean = 100\n",
        "population_std = 10  # Assumed known for Z-test\n",
        "\n",
        "# Step 2: Perform Z-test\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(n))\n",
        "z_p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "# Step 3: Perform T-test (one-sample)\n",
        "t_stat, t_p_value = stats.ttest_1samp(sample, population_mean)\n",
        "\n",
        "# Step 4: Results\n",
        "print(\"=== Z-Test Results ===\")\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {z_p_value:.4f}\")\n",
        "\n",
        "print(\"\\n=== T-Test Results ===\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {t_p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "print(\"\\n=== Interpretation ===\")\n",
        "if z_p_value < alpha:\n",
        "    print(\"Z-test: Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Z-test: Fail to reject the null hypothesis (no significant difference).\")\n",
        "\n",
        "if t_p_value < alpha:\n",
        "    print(\"T-test: Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"T-test: Fail to reject the null hypothesis (no significant difference).\")"
      ],
      "metadata": {
        "id": "moQxQY0jZOtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q9] Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n",
        "\n",
        "Ans- import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for a sample mean.\n",
        "\n",
        "    Parameters:\n",
        "        data (list or array): Sample data\n",
        "        confidence (float): Confidence level (default is 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "        (mean, lower_bound, upper_bound)\n",
        "    \"\"\"\n",
        "    sample = np.array(data)\n",
        "    n = len(sample)\n",
        "    mean = np.mean(sample)\n",
        "    se = stats.sem(sample)  # Standard error of the mean\n",
        "    margin = stats.t.ppf((1 + confidence) / 2., n - 1) * se  # t-critical value\n",
        "\n",
        "    lower = mean - margin\n",
        "    upper = mean + margin\n",
        "\n",
        "    return mean, lower, upper\n",
        "üß™ Example Usage:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "# Simulated sample data\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=100, scale=15, size=25)\n",
        "\n",
        "# Calculate 95% confidence interval\n",
        "mean, lower, upper = confidence_interval(sample_data)\n",
        "\n",
        "print(f\"Sample Mean: {mean:.2f}\")\n",
        "print(f\"95% Confidence Interval: [{lower:.2f}, {upper:.2f}]\")"
      ],
      "metadata": {
        "id": "cIDHfvPZZbw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q10] Write a Python program to calculate the margin of error for a given confidence level using sample data.\n",
        "\n",
        "Ans- import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def margin_of_error(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the margin of error for the sample mean.\n",
        "\n",
        "    Parameters:\n",
        "        data (list or array): Sample data\n",
        "        confidence (float): Confidence level (default = 0.95)\n",
        "\n",
        "    Returns:\n",
        "        margin_of_error (float)\n",
        "    \"\"\"\n",
        "    sample = np.array(data)\n",
        "    n = len(sample)\n",
        "    se = stats.sem(sample)  # Standard error of the mean\n",
        "    t_critical = stats.t.ppf((1 + confidence) / 2., df=n-1)  # t critical value\n",
        "\n",
        "    moe = t_critical * se\n",
        "    return moe\n",
        "üß™ Example Usage:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "# Simulated sample data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=8, size=40)\n",
        "\n",
        "# Calculate Margin of Error for 95% confidence level\n",
        "moe_95 = margin_of_error(sample_data, confidence=0.95)\n",
        "print(f\"Margin of Error (95% CI): ¬±{moe_95:.2f}\")\n",
        "\n",
        "# Optional: Also show mean and confidence interval\n",
        "mean = np.mean(sample_data)\n",
        "print(f\"Sample Mean: {mean:.2f}\")\n",
        "print(f\"95% Confidence Interval: [{mean - moe_95:.2f}, {mean + moe_95:.2f}]\")"
      ],
      "metadata": {
        "id": "EFfH7Zc2Zp1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q11]  Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process.\n",
        "\n",
        "Ans- def bayes_theorem(prior, likelihood, false_positive, prevalence_complement=None):\n",
        "    \"\"\"\n",
        "    Apply Bayes' Theorem to calculate the posterior probability.\n",
        "\n",
        "    Parameters:\n",
        "        prior (float): P(D) - prior probability of the hypothesis\n",
        "        likelihood (float): P(Pos | D) - probability of evidence given hypothesis\n",
        "        false_positive (float): P(Pos | ~D) - false positive rate\n",
        "        prevalence_complement (float): P(~D) - optional, defaults to 1 - prior\n",
        "\n",
        "    Returns:\n",
        "        posterior (float): P(D | Pos) - updated probability after seeing evidence\n",
        "    \"\"\"\n",
        "    if prevalence_complement is None:\n",
        "        prevalence_complement = 1 - prior\n",
        "\n",
        "    # Total probability of the evidence\n",
        "    evidence = likelihood * prior + false_positive * prevalence_complement\n",
        "\n",
        "    # Bayes' Theorem\n",
        "    posterior = (likelihood * prior) / evidence\n",
        "    return posterior\n",
        "üß™ Example Usage:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "# Prior probability of having the disease\n",
        "prior = 0.01  # 1%\n",
        "\n",
        "# Likelihood: P(Positive | Disease)\n",
        "likelihood = 0.99\n",
        "\n",
        "# False positive rate: P(Positive | No Disease)\n",
        "false_positive = 0.05\n",
        "\n",
        "# Calculate posterior: P(Disease | Positive test)\n",
        "posterior = bayes_theorem(prior, likelihood, false_positive)\n",
        "print(f\"Posterior probability (Disease | Positive test): {posterior:.4f}\")"
      ],
      "metadata": {
        "id": "iTTnqiQXZ4n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q12] D Perform a Chi-square test for independence between two categorical variables in Python.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Step 1: Simulate categorical data\n",
        "data = {\n",
        "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female'],\n",
        "    'Preference': ['Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No']\n",
        "}\n",
        "\n",
        "# Step 2: Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 3: Create a contingency table\n",
        "contingency_table = pd.crosstab(df['Gender'], df['Preference'])\n",
        "print(\"Contingency Table:\\n\", contingency_table)\n",
        "\n",
        "# Step 4: Perform Chi-square test for independence\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Step 5: Output the results\n",
        "print(\"\\nChi-square Test Results:\")\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(f\"Expected Frequencies:\\n{expected}\")\n",
        "\n",
        "# Step 6: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: There is a significant association between Gender and Preference.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: There is no significant association between Gender and Preference.\")"
      ],
      "metadata": {
        "id": "S4hMTJeraMWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q13] Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_expected_frequencies(observed):\n",
        "    \"\"\"\n",
        "    Calculate the expected frequencies for a Chi-square test based on observed data.\n",
        "\n",
        "    Parameters:\n",
        "        observed (2D array or DataFrame): The observed frequencies in the contingency table.\n",
        "\n",
        "    Returns:\n",
        "        expected (2D array): The expected frequencies for each cell.\n",
        "    \"\"\"\n",
        "    # Convert the observed frequencies to a DataFrame if it's not already one\n",
        "    if isinstance(observed, np.ndarray):\n",
        "        observed = pd.DataFrame(observed)\n",
        "\n",
        "    # Calculate row totals, column totals, and grand total\n",
        "    row_totals = observed.sum(axis=1).values.reshape(-1, 1)\n",
        "    column_totals = observed.sum(axis=0).values\n",
        "    grand_total = observed.sum().sum()\n",
        "\n",
        "    # Calculate the expected frequencies\n",
        "    expected = (row_totals @ column_totals.reshape(1, -1)) / grand_total\n",
        "    return expected\n",
        "\n",
        "# Example Observed Data (Contingency Table)\n",
        "observed_data = np.array([[10, 20], [30, 40]])\n",
        "\n",
        "# Calculate expected frequencies\n",
        "expected_frequencies = calculate_expected_frequencies(observed_data)\n",
        "\n",
        "# Print the results\n",
        "print(\"Observed Frequencies:\\n\", observed_data)\n",
        "print(\"\\nExpected Frequencies:\\n\", expected_frequencies)"
      ],
      "metadata": {
        "id": "d_zYB1X3ad_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q14] Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution.\n",
        "\n",
        "Ans- import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Step 1: Define observed data (frequencies of categories)\n",
        "observed = np.array([50, 30, 20])  # Example observed frequencies for 3 categories\n",
        "\n",
        "# Step 2: Define expected data (frequencies under hypothesized distribution)\n",
        "# For example, we hypothesize an equal distribution (33% per category)\n",
        "expected = np.array([33.33, 33.33, 33.33])\n",
        "\n",
        "# Step 3: Perform the Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(observed, expected)\n",
        "\n",
        "# Step 4: Output the results\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: The observed data does not match the expected distribution.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: The observed data matches the expected distribution.\")\n"
      ],
      "metadata": {
        "id": "W60Pfi7yavpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q15] Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the number of samples\n",
        "num_samples = 10000\n",
        "\n",
        "# Set degrees of freedom for the Chi-square distribution (you can change this value)\n",
        "df = 5\n",
        "\n",
        "# Simulate Chi-square data using NumPy\n",
        "chi_square_data = np.random.chisquare(df, num_samples)\n",
        "\n",
        "# Plot the Chi-square distribution using Seaborn for better aesthetics\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(chi_square_data, bins=30, kde=False, color='skyblue', edgecolor='black')\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title(f'Chi-Square Distribution with {df} Degrees of Freedom', fontsize=16)\n",
        "plt.xlabel('Value', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print the characteristics\n",
        "print(f\"Chi-square Distribution Characteristics (df={df}):\")\n",
        "print(f\"Mean: {df}\")\n",
        "print(f\"Variance: {2 * df}\")"
      ],
      "metadata": {
        "id": "m-8ytr9La9tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q16]  Implement an F-test using Python to compare the variances of two random samples.\n",
        "\n",
        "Ans- import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "# Step 1: Simulate two random samples\n",
        "np.random.seed(42)\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=100)  # Sample 1 with mean=50, std=10\n",
        "sample2 = np.random.normal(loc=50, scale=15, size=100)  # Sample 2 with mean=50, std=15\n",
        "\n",
        "# Step 2: Calculate the variances of the samples\n",
        "var_sample1 = np.var(sample1, ddof=1)  # Sample variance with degrees of freedom = 1\n",
        "var_sample2 = np.var(sample2, ddof=1)\n",
        "\n",
        "# Step 3: Calculate the F statistic (the ratio of variances)\n",
        "F_statistic = var_sample1 / var_sample2  # The F statistic is the ratio of the variances\n",
        "\n",
        "# Step 4: Calculate the degrees of freedom for both samples\n",
        "df1 = len(sample1) - 1  # Degrees of freedom for sample 1\n",
        "df2 = len(sample2) - 1  # Degrees of freedom for sample 2\n",
        "\n",
        "# Step 5: Calculate the p-value using the F-distribution\n",
        "p_value = 1 - f.cdf(F_statistic, df1, df2)  # P-value for the right tail of the F-distribution\n",
        "\n",
        "# Step 6: Output the results\n",
        "print(f\"Variance of Sample 1: {var_sample1:.4f}\")\n",
        "print(f\"Variance of Sample 2: {var_sample2:.4f}\")\n",
        "print(f\"F-statistic: {F_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 7: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: The variances are not significantly different.\")\n"
      ],
      "metadata": {
        "id": "UNlkCDT3bPAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q17] Write a Python program to perform an ANOVA test to compare means between multiple groups and interpret the results.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Step 1: Simulate data for multiple groups\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate data for 3 different groups (e.g., three different treatments or conditions)\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)  # Group 1: Mean=50, Std=10\n",
        "group2 = np.random.normal(loc=55, scale=12, size=30)  # Group 2: Mean=55, Std=12\n",
        "group3 = np.random.normal(loc=60, scale=15, size=30)  # Group 3: Mean=60, Std=15\n",
        "\n",
        "# Step 2: Perform the One-Way ANOVA test\n",
        "F_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Step 3: Output the results\n",
        "print(f\"F-statistic: {F_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: There is a significant difference between the means.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: There is no significant difference between the means.\")"
      ],
      "metadata": {
        "id": "bcvjR-tnbilo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q18] Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Simulate data for multiple groups\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate data for 3 different groups (e.g., three different treatments or conditions)\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)  # Group 1: Mean=50, Std=10\n",
        "group2 = np.random.normal(loc=55, scale=12, size=30)  # Group 2: Mean=55, Std=12\n",
        "group3 = np.random.normal(loc=60, scale=15, size=30)  # Group 3: Mean=60, Std=15\n",
        "\n",
        "# Step 2: Perform the One-Way ANOVA test\n",
        "F_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Step 3: Output the results\n",
        "print(f\"F-statistic: {F_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: There is a significant difference between the means.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: There is no significant difference between the means.\")\n",
        "\n",
        "# Step 5: Visualize the data using a box plot\n",
        "# Combine the data into a list for plotting\n",
        "data = [group1, group2, group3]\n",
        "group_labels = ['Group 1', 'Group 2', 'Group 3']\n",
        "\n",
        "# Set up the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=data, tick_params='inside')\n",
        "plt.xticks(np.arange(3), group_labels)\n",
        "plt.title(\"One-Way ANOVA: Group Comparison\", fontsize=16)\n",
        "plt.xlabel(\"Group\", fontsize=12)\n",
        "plt.ylabel(\"Values\", fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HnRfx0jpbzS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q19] Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def check_anova_assumptions(groups):\n",
        "    \"\"\"\n",
        "    Check the assumptions for one-way ANOVA:\n",
        "    - Normality (Shapiro-Wilk test)\n",
        "    - Equal variance (Levene's test)\n",
        "    \"\"\"\n",
        "    # 1. Check normality using Shapiro-Wilk test for each group\n",
        "    print(\"Checking normality assumption using Shapiro-Wilk test:\")\n",
        "    normality_results = {}\n",
        "    for i, group in enumerate(groups):\n",
        "        stat, p_value = stats.shapiro(group)\n",
        "        normality_results[f'Group {i+1}'] = (stat, p_value)\n",
        "        print(f\"Group {i+1}: Statistic = {stat:.4f}, p-value = {p_value:.4f}\")\n",
        "        if p_value < 0.05:\n",
        "            print(f\"  => Reject the null hypothesis: Group {i+1} is not normally distributed.\")\n",
        "        else:\n",
        "            print(f\"  => Fail to reject the null hypothesis: Group {i+1} is normally distributed.\")\n",
        "\n",
        "    # 2. Check equal variances using Levene's test\n",
        "    print(\"\\nChecking homogeneity of variance assumption using Levene's test:\")\n",
        "    stat, p_value = stats.levene(*groups)\n",
        "    print(f\"Levene's test statistic: {stat:.4f}, p-value = {p_value:.4f}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"  => Reject the null hypothesis: Variances are not equal (heteroscedasticity).\")\n",
        "    else:\n",
        "        print(\"  => Fail to reject the null hypothesis: Variances are equal (homoscedasticity).\")\n",
        "\n",
        "    # 3. Visualization of group data to inspect normality and variances\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(data=groups)\n",
        "    plt.title(\"Box Plot to Inspect Normality and Equal Variance Assumptions\")\n",
        "    plt.xlabel(\"Groups\")\n",
        "    plt.ylabel(\"Values\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulate data for 3 different groups\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)  # Group 1\n",
        "group2 = np.random.normal(loc=55, scale=12, size=30)  # Group 2\n",
        "group3 = np.random.normal(loc=60, scale=15, size=30)  # Group 3\n",
        "\n",
        "# Combine the groups into a list\n",
        "groups = [group1, group2, group3]\n",
        "\n",
        "# Call the function to check assumptions\n",
        "check_anova_assumptions(groups)"
      ],
      "metadata": {
        "id": "eFrPsELxb-Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q20] D Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the results.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "# Step 1: Simulate data for two factors (e.g., treatment and time)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Factor 1: Treatment (2 levels: 'A' and 'B')\n",
        "# Factor 2: Time (3 levels: 'T1', 'T2', 'T3')\n",
        "treatment = ['A', 'B']\n",
        "time = ['T1', 'T2', 'T3']\n",
        "\n",
        "# Simulating the data\n",
        "data = []\n",
        "for t in treatment:\n",
        "    for ti in time:\n",
        "        # Random data generation for each treatment and time combination\n",
        "        mean = 50 if t == 'A' else 55  # Different means for treatments A and B\n",
        "        std_dev = 10 + np.random.uniform(0, 3)  # Varying standard deviation\n",
        "        group_data = np.random.normal(loc=mean, scale=std_dev, size=30)  # 30 samples per group\n",
        "        data.append(pd.DataFrame({\n",
        "            'Treatment': t,\n",
        "            'Time': ti,\n",
        "            'Value': group_data\n",
        "        }))\n",
        "\n",
        "# Combine all data into a single DataFrame\n",
        "df = pd.concat(data, ignore_index=True)\n",
        "\n",
        "# Step 2: Perform Two-Way ANOVA\n",
        "model = ols('Value ~ C(Treatment) + C(Time) + C(Treatment):C(Time)', data=df).fit()\n",
        "anova_table = anova_lm(model, typ=2)  # Type II ANOVA\n",
        "\n",
        "# Print the ANOVA table\n",
        "print(anova_table)\n",
        "\n",
        "# Step 3: Interpret the Results\n",
        "alpha = 0.05\n",
        "if anova_table['PR(>F)']['C(Treatment)'] < alpha:\n",
        "    print(\"\\nReject the null hypothesis for Treatment: There is a significant effect of Treatment.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis for Treatment: No significant effect of Treatment.\")\n",
        "\n",
        "if anova_table['PR(>F)']['C(Time)'] < alpha:\n",
        "    print(\"Reject the null hypothesis for Time: There is a significant effect of Time.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis for Time: No significant effect of Time.\")\n",
        "\n",
        "if anova_table['PR(>F)']['C(Treatment):C(Time)'] < alpha:\n",
        "    print(\"Reject the null hypothesis for Interaction: There is a significant interaction effect between Treatment and Time.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis for Interaction: No significant interaction effect between Treatment and Time.\")\n",
        "\n",
        "# Step 4: Visualize the results\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Create interaction plot\n",
        "sns.pointplot(x='Time', y='Value', hue='Treatment', data=df, markers='o', linestyles='-', ci=None)\n",
        "plt.title(\"Interaction Plot: Treatment and Time Effects\", fontsize=16)\n",
        "plt.xlabel(\"Time\", fontsize=12)\n",
        "plt.ylabel(\"Value\", fontsize=12)\n",
        "plt.legend(title='Treatment')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nQpTUl4lcMYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q21] D Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Set degrees of freedom for numerator and denominator\n",
        "df1 = [1, 2, 5]  # Different degrees of freedom for the numerator\n",
        "df2 = [5, 10, 20]  # Different degrees of freedom for the denominator\n",
        "\n",
        "# Generate x values for plotting (range of F-statistics)\n",
        "x = np.linspace(0, 5, 1000)\n",
        "\n",
        "# Plot the F-distributions for different degrees of freedom\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for d1 in df1:\n",
        "    for d2 in df2:\n",
        "        # Calculate the F-distribution for given df1 and df2\n",
        "        y = stats.f.pdf(x, d1, d2)\n",
        "        plt.plot(x, y, label=f'df1={d1}, df2={d2}')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('F-distribution with Different Degrees of Freedom', fontsize=16)\n",
        "plt.xlabel('F-statistic', fontsize=12)\n",
        "plt.ylabel('Density', fontsize=12)\n",
        "plt.legend(title='Degrees of Freedom')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o341UcmLcbTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q22] Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Simulate some data for three different groups\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulating data for 3 groups (e.g., different treatment types)\n",
        "group_1 = np.random.normal(loc=50, scale=10, size=30)  # Group 1 mean=50, std=10\n",
        "group_2 = np.random.normal(loc=55, scale=10, size=30)  # Group 2 mean=55, std=10\n",
        "group_3 = np.random.normal(loc=60, scale=10, size=30)  # Group 3 mean=60, std=10\n",
        "\n",
        "# Combine the data into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'Value': np.concatenate([group_1, group_2, group_3]),\n",
        "    'Group': ['Group 1']*30 + ['Group 2']*30 + ['Group 3']*30\n",
        "})\n",
        "\n",
        "# Step 2: Perform a One-Way ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(group_1, group_2, group_3)\n",
        "\n",
        "# Print the result\n",
        "print(f\"ANOVA Test Result: F-statistic = {f_statistic:.2f}, p-value = {p_value:.4f}\")\n",
        "\n",
        "# Step 3: Interpret the results\n",
        "alpha = 0.05  # significance level\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: There is a significant difference between the group means.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: There is no significant difference between the group means.\")\n",
        "\n",
        "# Step 4: Visualize the results using boxplots\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Group', y='Value', data=data)\n",
        "plt.title('Boxplot of Values by Group', fontsize=16)\n",
        "plt.xlabel('Group', fontsize=12)\n",
        "plt.ylabel('Value', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C-gclqs2cmNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q23] Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate random data from normal distribution\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulate data for two groups (control and treatment)\n",
        "group_1 = np.random.normal(loc=50, scale=10, size=100)  # Group 1: mean=50, std=10\n",
        "group_2 = np.random.normal(loc=55, scale=10, size=100)  # Group 2: mean=55, std=10\n",
        "\n",
        "# Step 2: Perform a Two-Sample t-test\n",
        "t_statistic, p_value = stats.ttest_ind(group_1, group_2)\n",
        "\n",
        "# Step 3: Print the results of the t-test\n",
        "print(f\"T-statistic: {t_statistic:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpret the results\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: The means of the two groups are significantly different.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: The means of the two groups are not significantly different.\")\n",
        "\n",
        "# Step 5: Visualize the distributions of the two groups\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot histograms for both groups\n",
        "plt.hist(group_1, bins=20, alpha=0.6, label='Group 1 (Control)', color='blue')\n",
        "plt.hist(group_2, bins=20, alpha=0.6, label='Group 2 (Treatment)', color='green')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Distribution of Two Groups', fontsize=16)\n",
        "plt.xlabel('Value', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OQxGs2NDcwsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q24] Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Step 1: Simulate sample data\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data from a normal distribution\n",
        "\n",
        "# Step 2: Define hypothesized population variance\n",
        "hypothesized_variance = 100  # Hypothesized population variance (sigma_0^2)\n",
        "\n",
        "# Step 3: Calculate sample variance (s^2) and sample size (n)\n",
        "sample_variance = np.var(sample_data, ddof=1)  # Sample variance with degrees of freedom = 1\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "# Step 4: Calculate the Chi-square statistic\n",
        "chi_square_statistic = (sample_size - 1) * sample_variance / hypothesized_variance\n",
        "\n",
        "# Step 5: Calculate the degrees of freedom\n",
        "degrees_of_freedom = sample_size - 1\n",
        "\n",
        "# Step 6: Determine the critical value from the Chi-square distribution\n",
        "alpha = 0.05  # Significance level\n",
        "chi_square_critical_low = stats.chi2.ppf(alpha / 2, degrees_of_freedom)  # Lower critical value\n",
        "chi_square_critical_high = stats.chi2.ppf(1 - alpha / 2, degrees_of_freedom)  # Upper critical value\n",
        "\n",
        "# Step 7: Print the results\n",
        "print(f\"Sample Variance: {sample_variance:.2f}\")\n",
        "print(f\"Chi-Square Statistic: {chi_square_statistic:.2f}\")\n",
        "print(f\"Critical values: Lower = {chi_square_critical_low:.2f}, Upper = {chi_square_critical_high:.2f}\")\n",
        "\n",
        "# Step 8: Interpret the results\n",
        "if chi_square_statistic < chi_square_critical_low or chi_square_statistic > chi_square_critical_high:\n",
        "    print(\"\\nReject the null hypothesis: The population variance is significantly different from the hypothesized value.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: The population variance is not significantly different from the hypothesized value.\")"
      ],
      "metadata": {
        "id": "8T8lJFXXdAmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q25]  Write a Python script to perform a Z-test for comparing proportions between two datasets or groups.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Step 1: Simulate data for two groups (e.g., success vs. failure rates)\n",
        "# Sample 1 (group 1): 100 successes out of 200 trials\n",
        "# Sample 2 (group 2): 120 successes out of 220 trials\n",
        "x1, n1 = 100, 200  # Successes and total trials for group 1\n",
        "x2, n2 = 120, 220  # Successes and total trials for group 2\n",
        "\n",
        "# Step 2: Calculate the sample proportions\n",
        "p1 = x1 / n1  # Proportion for group 1\n",
        "p2 = x2 / n2  # Proportion for group 2\n",
        "\n",
        "# Step 3: Calculate the pooled proportion\n",
        "p = (x1 + x2) / (n1 + n2)\n",
        "\n",
        "# Step 4: Calculate the standard error\n",
        "se = np.sqrt(p * (1 - p) * (1 / n1 + 1 / n2))\n",
        "\n",
        "# Step 5: Calculate the Z statistic\n",
        "z_statistic = (p1 - p2) / se\n",
        "\n",
        "# Step 6: Calculate the p-value\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))  # Two-tailed test\n",
        "\n",
        "# Step 7: Print the results\n",
        "print(f\"Sample Proportions: p1 = {p1:.3f}, p2 = {p2:.3f}\")\n",
        "print(f\"Z-statistic: {z_statistic:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 8: Interpret the results\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: The proportions are significantly different.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: The proportions are not significantly different.\")"
      ],
      "metadata": {
        "id": "UNXbzrvddYog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q26] Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate two datasets\n",
        "np.random.seed(42)\n",
        "data1 = np.random.normal(loc=50, scale=10, size=100)  # Dataset 1 (mean = 50, std dev = 10)\n",
        "data2 = np.random.normal(loc=50, scale=15, size=100)  # Dataset 2 (mean = 50, std dev = 15)\n",
        "\n",
        "# Step 2: Calculate sample variances\n",
        "var1 = np.var(data1, ddof=1)  # Sample variance for dataset 1\n",
        "var2 = np.var(data2, ddof=1)  # Sample variance for dataset 2\n",
        "\n",
        "# Step 3: Compute the F-statistic (larger variance / smaller variance)\n",
        "f_statistic = max(var1, var2) / min(var1, var2)\n",
        "\n",
        "# Step 4: Degrees of freedom for both samples\n",
        "df1 = len(data1) - 1\n",
        "df2 = len(data2) - 1\n",
        "\n",
        "# Step 5: Calculate the p-value from the F-distribution\n",
        "p_value = 2 * min(stats.f.cdf(f_statistic, df1, df2), 1 - stats.f.cdf(f_statistic, df1, df2))\n",
        "\n",
        "# Step 6: Print results\n",
        "print(f\"Sample Variances: var1 = {var1:.2f}, var2 = {var2:.2f}\")\n",
        "print(f\"F-statistic: {f_statistic:.2f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 7: Interpret the results\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: The variances are not significantly different.\")\n",
        "\n",
        "# Step 8: Visualize the F-distribution and F-statistic\n",
        "x = np.linspace(0, 5, 500)\n",
        "y = stats.f.pdf(x, df1, df2)\n",
        "\n",
        "plt.plot(x, y, label=f'F-distribution (df1={df1}, df2={df2})')\n",
        "plt.axvline(f_statistic, color='red', linestyle='--', label=f'F-statistic = {f_statistic:.2f}')\n",
        "plt.title('F-distribution and F-statistic')\n",
        "plt.xlabel('F-value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VZhyVsqVdrP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q27]  Perform a Chi-square test for goodness of fit with simulated data and analyze the results.\n",
        "\n",
        "Ans- import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate observed data (e.g., data representing the outcomes of rolling a fair die 100 times)\n",
        "observed_data = np.array([18, 15, 17, 20, 15, 15])  # Observed frequencies for each face of a die\n",
        "\n",
        "# Step 2: Define expected frequencies for a fair die (expected uniform distribution)\n",
        "expected_data = np.array([100/6] * 6)  # Expected frequency for each outcome if the die is fair (expected = 16.67)\n",
        "\n",
        "# Step 3: Perform the Chi-square goodness of fit test\n",
        "chi2_statistic, p_value = stats.chisquare(observed_data, expected_data)\n",
        "\n",
        "# Step 4: Print the results\n",
        "print(f\"Observed Frequencies: {observed_data}\")\n",
        "print(f\"Expected Frequencies: {expected_data}\")\n",
        "print(f\"Chi-square statistic: {chi2_statistic:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpret the results\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"\\nReject the null hypothesis: The data does not follow the expected distribution.\")\n",
        "else:\n",
        "    print(\"\\nFail to reject the null hypothesis: The data follows the expected distribution.\")\n",
        "\n",
        "# Step 6: Visualize the observed vs expected frequencies using a bar plot\n",
        "categories = ['1', '2', '3', '4', '5', '6']  # Categories for the die faces\n",
        "\n",
        "x = np.arange(len(categories))  # x-axis positions\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "ax.bar(x - 0.2, observed_data, 0.4, label='Observed', color='blue')\n",
        "ax.bar(x + 0.2, expected_data, 0.4, label='Expected', color='red')\n",
        "\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(categories)\n",
        "ax.set_xlabel('Die Face')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Chi-square Goodness of Fit Test: Observed vs Expected Frequencies')\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9J1qLZyzd5pF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}